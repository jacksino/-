{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b0c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "def stitch(path1, path2):\n",
    "    \"\"\"\n",
    "    传入图片路径，返回变换过后的填充图片\n",
    "    :param path1:\n",
    "    :param path2:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 边界填充\n",
    "    top, bot, left, right = 100, 100, 0, 800\n",
    "    img1 = cv2.imread(path1)\n",
    "    img2 = cv2.imread(path2)\n",
    "    img1_size = img1.shape[:2]\n",
    "    img2 = cv2.resize(img2, (img1_size[1], img1_size[0]))\n",
    "\n",
    "    srcImg = cv2.copyMakeBorder(img1, top, bot, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "    testImg = cv2.copyMakeBorder(img2, top, bot, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "    img1gray = cv2.cvtColor(srcImg, cv2.COLOR_BGR2GRAY)\n",
    "    img2gray = cv2.cvtColor(testImg, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    # SIFT关键点匹配\n",
    "    kp1, des1 = sift.detectAndCompute(img1gray, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2gray, None)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # 掩膜筛选出好的关键点\n",
    "    matchesMask = [[0, 0] for i in range(len(matches))]\n",
    "    good = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    # 随机测试\n",
    "    for i, (m, n) in enumerate(matches):\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            good.append(m)\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "            matchesMask[i] = [1, 0]\n",
    "\n",
    "    draw_params = dict(matchColor=(0, 255, 0),\n",
    "                       singlePointColor=(255, 0, 0),\n",
    "                       matchesMask=matchesMask,\n",
    "                       flags=0)\n",
    "    img3 = cv2.drawMatchesKnn(img1gray, kp1, img2gray, kp2, matches, None, **draw_params)\n",
    "    plt.imshow(img3, ), plt.show()\n",
    "\n",
    "    MIN_MATCH_COUNT = 10\n",
    "    if len(good) > MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        warpImg = cv2.warpPerspective(testImg, np.array(M), (testImg.shape[1], testImg.shape[0]),\n",
    "                                      flags=cv2.WARP_INVERSE_MAP)\n",
    "        return srcImg, warpImg\n",
    "    else:\n",
    "        print(\"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT))\n",
    "        matchesMask = None\n",
    "\n",
    "\n",
    "def blend(srcImg, warpImg, savename=None):\n",
    "    \"\"\"\n",
    "    图片融合，\n",
    "    \"\"\"\n",
    "    rows, cols = srcImg.shape[:2]\n",
    "    # 找到左右重叠区域\n",
    "    global left, right\n",
    "    for col in range(0, cols):\n",
    "        if srcImg[:, col].any() and warpImg[:, col].any():\n",
    "            left = col\n",
    "            break\n",
    "    for col in range(cols - 1, 0, -1):\n",
    "        if srcImg[:, col].any() and warpImg[:, col].any():\n",
    "            right = col\n",
    "            break\n",
    "\n",
    "    res = np.zeros([rows, cols, 3], np.uint8)\n",
    "    alpha = np.zeros((rows, right - left, 3), dtype=np.float)\n",
    "    for row in range(0, rows):\n",
    "        for col in range(left, right):\n",
    "            if not srcImg[row, col].any():  # src不存在\n",
    "                alpha[row, col - left, :] = 0\n",
    "            elif not warpImg[row, col].any():  # warpImg 不存在\n",
    "                alpha[row, col - left, :] = 1\n",
    "            else:  # src 和warp都存在\n",
    "                srcImgLen = float(abs(col - left))\n",
    "                testImgLen = float(abs(col - right))\n",
    "                alpha[row, col - left, :] = testImgLen / (srcImgLen + testImgLen)\n",
    "\n",
    "    res[:, :left] = srcImg[:, :left]\n",
    "    res[:, right:] = warpImg[:, right:]\n",
    "    res[:, left:right] = np.clip(srcImg[:, left:right] * alpha + warpImg[:, left:right] * (np.ones_like(alpha) - alpha),\n",
    "                                 0, 255)\n",
    "\n",
    "    # opencv is bgr, matplotlib is rgb\n",
    "    res = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
    "    if savename is not None:\n",
    "        plt.imsave(savename, res)\n",
    "    return res\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path1 = 'data/1.jpg'\n",
    "    path2 = 'data/2.jpg'\n",
    "#     path3 = 'data/3.jpg'\n",
    "#     path4 = 'data/4.jpg'\n",
    "#     path5 = 'stitch12.jpg'\n",
    "#     path6 = 'stitch34.jpg'\n",
    "#     res12 = 'data/stitch12.jpg'\n",
    "#     res34 = 'data/stitch34.jpg'\n",
    "\n",
    "    srcImg, warpImg = stitch(path1, path2)\n",
    "    start = time.time()\n",
    "    res = blend(srcImg, warpImg, 'stitch12.jpg')\n",
    "    end = time.time()\n",
    "    print('融合时间：', end - start)\n",
    "    # show the result\n",
    "    plt.figure()\n",
    "    plt.imshow(res)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
